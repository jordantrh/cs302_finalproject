{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d69fe1f-2cd4-4f6f-b9c7-a3b6de0a9368",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 25 16:30:34 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 528.02       Driver Version: 528.02       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   58C    P0    31W / 140W |      0MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23270abe-03af-42f6-8e04-359713211a85",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\jorda\\anaconda3\\lib\\site-packages (8.0.86)\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.0.88-py3-none-any.whl (530 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ultralytics) (8.4.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ultralytics) (1.7.1)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ultralytics) (0.15.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ultralytics) (4.7.0.72)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ultralytics) (1.3.4)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ultralytics) (3.4.3)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ultralytics) (0.11.2)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ultralytics) (2.0.0)\n",
      "Requirement already satisfied: sentry-sdk in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ultralytics) (1.20.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ultralytics) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ultralytics) (4.65.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ultralytics) (5.8.0)\n",
      "Requirement already satisfied: numpy>=1.21.6 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ultralytics) (1.22.4)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ultralytics) (2.26.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.2.2->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2021.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2022.12.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from torch>=1.7.0->ultralytics) (2.11.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from torch>=1.7.0->ultralytics) (2.6.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from torch>=1.7.0->ultralytics) (1.9)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from torch>=1.7.0->ultralytics) (3.10.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from torch>=1.7.0->ultralytics) (3.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.7.0->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from sympy->torch>=1.7.0->ultralytics) (1.2.1)\n",
      "Installing collected packages: ultralytics\n",
      "  Attempting uninstall: ultralytics\n",
      "    Found existing installation: ultralytics 8.0.86\n",
      "    Uninstalling ultralytics-8.0.86:\n",
      "      Successfully uninstalled ultralytics-8.0.86\n",
      "Successfully installed ultralytics-8.0.88\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61223b3f-3d17-40d4-9c84-a5515605207d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pathlib in c:\\users\\jorda\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: ruamel-yaml in c:\\users\\jorda\\anaconda3\\lib\\site-packages (0.17.21)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.6 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ruamel-yaml) (0.2.7)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\jorda\\anaconda3\\lib\\site-packages (3.10.0.2)\n",
      "Requirement already satisfied: roboflow in c:\\users\\jorda\\anaconda3\\lib\\site-packages (1.0.5)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: idna==2.10 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (0.10.1)\n",
      "Requirement already satisfied: requests in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (1.22.4)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (4.65.0)\n",
      "Requirement already satisfied: cycler==0.10.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (1.26.15)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (2.4.7)\n",
      "Requirement already satisfied: certifi==2022.12.7 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (2022.12.7)\n",
      "Requirement already satisfied: wget in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (3.2)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (8.4.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (3.4.3)\n",
      "Requirement already satisfied: six in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.2 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (4.7.0.72)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (6.0)\n",
      "Requirement already satisfied: chardet==4.0.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from requests->roboflow) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pathlib\n",
    "!pip install ruamel-yaml\n",
    "!pip install typing-extensions\n",
    "!pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07fc38d4-061e-41f6-8cbd-e24e01cd43d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\n",
      "\u001b[2K\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.88  Python-3.9.7 torch-2.0.0+cpu CPU\n",
      "Setup complete  (16 CPUs, 15.7 GB RAM, 836.6/931.1 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import traceback\n",
    "import tellopy\n",
    "import av\n",
    "import cv2\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from ultralytics.yolo.v8.detect.predict import DetectionPredictor\n",
    "\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "!yolo checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2e45cf5-b9ac-4491-a989-dc822759489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"runs/detect/train5/weights/best.pt\")\n",
    "model.predict(source=\"0\", show=True, conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18666ad2-54ec-4ea1-b16f-eaca98eba5ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11768/1351637692.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mprocess\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mrgbframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mface_locations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgbframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mface_encodings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_encodings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgbframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mface_locations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mface_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\face_recognition\\api.py\u001b[0m in \u001b[0;36mface_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_trim_css_to_bounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_rect_to_css\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_raw_face_locations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cnn\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_trim_css_to_bounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_rect_to_css\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_raw_face_locations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\face_recognition\\api.py\u001b[0m in \u001b[0;36m_raw_face_locations\u001b[1;34m(img, number_of_times_to_upsample, model)\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcnn_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_times_to_upsample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# if you want to detect yourself, add (img_path, name) tuples to the input_face_pairs list below\n",
    "input_face_pairs = [('jordan.jpg', 'jordan')]\n",
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "\n",
    "for path, name in input_face_pairs:\n",
    "    image = face_recognition.load_image_file(path)\n",
    "    encoding = face_recognition.face_encodings(image)[0]\n",
    "    known_face_encodings.append(encoding)\n",
    "    known_face_names.append(name)\n",
    "\n",
    "face_locations = []\n",
    "face_encodings = []\n",
    "face_names = []\n",
    "\n",
    "vid = cv2.VideoCapture(0)\n",
    "process = 0\n",
    "while(True):\n",
    "\n",
    "    ret, frame = video_capture.read()\n",
    "    if process % 2 == 0:\n",
    "        rgbframe = frame[:, :, ::-1]\n",
    "        face_locations = face_recognition.face_locations(rgbframe)\n",
    "        face_encodings = face_recognition.face_encodings(rgbframe, face_locations)\n",
    "        face_names = []\n",
    "        for face_encoding in face_encodings:\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            if face_distances:\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                if matches[best_match_index]:\n",
    "                    name = known_face_names[best_match_index]\n",
    "            face_names.append(name)\n",
    "    \n",
    "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2)\n",
    "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), cv2.FILLED)\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
    "\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    process += 1\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf4f15-f849-458c-9d2a-058a58c6bdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"runs/detect/train5/weights/best.pt\")\n",
    "model.predict(source=\"0\", show=True, conf=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114629dd-9c69-4e75-a52f-7b6129fcd866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bee731-9ca1-4d33-8d8a-0233273da10d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d56cb7b-dd87-4643-ab38-fd78d2465efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5945b92-fc5d-40d0-a95e-e63d1c6b85c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11768/152698847.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mFILE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mROOT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFILE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# yolov5 strongsort root directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mWEIGHTS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mROOT\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'weights'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import os\n",
    "# limit the number of cpus used by high performance libraries\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "# need to change b/c operating in notebook\n",
    "# link to model?\n",
    "FILE = Path(__file__).resolve()\n",
    "\n",
    "ROOT = FILE.parents[0]  # yolov5 strongsort root directory\n",
    "WEIGHTS = ROOT / 'weights'\n",
    "\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "if str(ROOT / 'yolov8') not in sys.path:\n",
    "    sys.path.append(str(ROOT / 'yolov8'))  # add yolov5 ROOT to PATH\n",
    "if str(ROOT / 'trackers' / 'strongsort') not in sys.path:\n",
    "    sys.path.append(str(ROOT / 'trackers' / 'strongsort'))  # add strong_sort ROOT to PATH\n",
    "\n",
    "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n",
    "\n",
    "import logging\n",
    "from yolov8.ultralytics.nn.autobackend import AutoBackend\n",
    "from yolov8.ultralytics.yolo.data.dataloaders.stream_loaders import LoadImages, LoadStreams\n",
    "from yolov8.ultralytics.yolo.data.utils import IMG_FORMATS, VID_FORMATS\n",
    "from yolov8.ultralytics.yolo.utils import DEFAULT_CFG, LOGGER, SETTINGS, callbacks, colorstr, ops\n",
    "from yolov8.ultralytics.yolo.utils.checks import check_file, check_imgsz, check_imshow, print_args, check_requirements\n",
    "from yolov8.ultralytics.yolo.utils.files import increment_path\n",
    "from yolov8.ultralytics.yolo.utils.torch_utils import select_device\n",
    "from yolov8.ultralytics.yolo.utils.ops import Profile, non_max_suppression, scale_boxes, process_mask, process_mask_native\n",
    "from yolov8.ultralytics.yolo.utils.plotting import Annotator, colors, save_one_box\n",
    "\n",
    "from trackers.multi_tracker_zoo import create_tracker\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def run(\n",
    "        source='0',\n",
    "        yolo_weights=WEIGHTS / 'yolov5m.pt',  # model.pt path(s),\n",
    "        reid_weights=WEIGHTS / 'osnet_x0_25_msmt17.pt',  # model.pt path,\n",
    "        tracking_method='strongsort',\n",
    "        tracking_config=None,\n",
    "        imgsz=(640, 640),  # inference size (height, width)\n",
    "        conf_thres=0.25,  # confidence threshold\n",
    "        iou_thres=0.45,  # NMS IOU threshold\n",
    "        max_det=1000,  # maximum detections per image\n",
    "        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "        show_vid=False,  # show results\n",
    "        save_txt=False,  # save results to *.txt\n",
    "        save_conf=False,  # save confidences in --save-txt labels\n",
    "        save_crop=False,  # save cropped prediction boxes\n",
    "        save_trajectories=False,  # save trajectories for each track\n",
    "        save_vid=False,  # save confidences in --save-txt labels\n",
    "        nosave=False,  # do not save images/videos\n",
    "        classes=None,  # filter by class: --class 0, or --class 0 2 3\n",
    "        agnostic_nms=False,  # class-agnostic NMS\n",
    "        augment=False,  # augmented inference\n",
    "        visualize=False,  # visualize features\n",
    "        update=False,  # update all models\n",
    "        project=ROOT / 'runs' / 'track',  # save results to project/name\n",
    "        name='exp',  # save results to project/name\n",
    "        exist_ok=False,  # existing project/name ok, do not increment\n",
    "        line_thickness=2,  # bounding box thickness (pixels)\n",
    "        hide_labels=False,  # hide labels\n",
    "        hide_conf=False,  # hide confidences\n",
    "        hide_class=False,  # hide IDs\n",
    "        half=False,  # use FP16 half-precision inference\n",
    "        dnn=False,  # use OpenCV DNN for ONNX inference\n",
    "        vid_stride=1,  # video frame-rate stride\n",
    "        retina_masks=False,\n",
    "):\n",
    "\n",
    "    source = str(source)\n",
    "    save_img = not nosave and not source.endswith('.txt')  # save inference images\n",
    "    is_file = Path(source).suffix[1:] in (VID_FORMATS)\n",
    "    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
    "    webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file)\n",
    "    if is_url and is_file:\n",
    "        source = check_file(source)  # download\n",
    "\n",
    "    # Directories\n",
    "    if not isinstance(yolo_weights, list):  # single yolo model\n",
    "        exp_name = yolo_weights.stem\n",
    "    elif type(yolo_weights) is list and len(yolo_weights) == 1:  # single models after --yolo_weights\n",
    "        exp_name = Path(yolo_weights[0]).stem\n",
    "    else:  # multiple models after --yolo_weights\n",
    "        exp_name = 'ensemble'\n",
    "    exp_name = name if name else exp_name + \"_\" + reid_weights.stem\n",
    "    save_dir = increment_path(Path(project) / exp_name, exist_ok=exist_ok)  # increment run\n",
    "    (save_dir / 'tracks' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "    # Load model\n",
    "    device = select_device(device)\n",
    "    is_seg = '-seg' in str(yolo_weights)\n",
    "    model = AutoBackend(yolo_weights, device=device, dnn=dnn, fp16=half)\n",
    "    stride, names, pt = model.stride, model.names, model.pt\n",
    "    imgsz = check_imgsz(imgsz, stride=stride)  # check image size\n",
    "\n",
    "    # Dataloader\n",
    "    bs = 1\n",
    "    if webcam:\n",
    "        show_vid = check_imshow(warn=True)\n",
    "        dataset = LoadStreams(\n",
    "            source,\n",
    "            imgsz=imgsz,\n",
    "            stride=stride,\n",
    "            auto=pt,\n",
    "            transforms=getattr(model.model, 'transforms', None),\n",
    "            vid_stride=vid_stride\n",
    "        )\n",
    "        bs = len(dataset)\n",
    "    else:\n",
    "        dataset = LoadImages(\n",
    "            source,\n",
    "            imgsz=imgsz,\n",
    "            stride=stride,\n",
    "            auto=pt,\n",
    "            transforms=getattr(model.model, 'transforms', None),\n",
    "            vid_stride=vid_stride\n",
    "        )\n",
    "    vid_path, vid_writer, txt_path = [None] * bs, [None] * bs, [None] * bs\n",
    "    model.warmup(imgsz=(1 if pt or model.triton else bs, 3, *imgsz))  # warmup\n",
    "\n",
    "    # Create as many strong sort instances as there are video sources\n",
    "    tracker_list = []\n",
    "    for i in range(bs):\n",
    "        tracker = create_tracker(tracking_method, tracking_config, reid_weights, device, half)\n",
    "        tracker_list.append(tracker, )\n",
    "        if hasattr(tracker_list[i], 'model'):\n",
    "            if hasattr(tracker_list[i].model, 'warmup'):\n",
    "                tracker_list[i].model.warmup()\n",
    "    outputs = [None] * bs\n",
    "\n",
    "    # Run tracking\n",
    "    #model.warmup(imgsz=(1 if pt else bs, 3, *imgsz))  # warmup\n",
    "    seen, windows, dt = 0, [], (Profile(), Profile(), Profile(), Profile())\n",
    "    curr_frames, prev_frames = [None] * bs, [None] * bs\n",
    "    \n",
    "    \n",
    "    \n",
    "    for frame_idx, batch in enumerate(dataset):\n",
    "        path, im, im0s, vid_cap, s = batch\n",
    "        visualize = increment_path(save_dir / Path(path[0]).stem, mkdir=True) if visualize else False\n",
    "        with dt[0]:\n",
    "            im = torch.from_numpy(im).to(device)\n",
    "            im = im.half() if half else im.float()  # uint8 to fp16/32\n",
    "            im /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "            if len(im.shape) == 3:\n",
    "                im = im[None]  # expand for batch dim\n",
    "\n",
    "        # Inference\n",
    "        with dt[1]:\n",
    "            preds = model(im, augment=augment, visualize=visualize)\n",
    "\n",
    "        # Apply NMS\n",
    "        with dt[2]:\n",
    "            if is_seg:\n",
    "                masks = []\n",
    "                p = non_max_suppression(preds[0], conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det, nm=32)\n",
    "                proto = preds[1][-1]\n",
    "            else:\n",
    "                p = non_max_suppression(preds, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
    "            \n",
    "        # Process detections\n",
    "        for i, det in enumerate(p):  # detections per image\n",
    "            seen += 1\n",
    "            if webcam:  # bs >= 1\n",
    "                p, im0, _ = path[i], im0s[i].copy(), dataset.count\n",
    "                p = Path(p)  # to Path\n",
    "                s += f'{i}: '\n",
    "                txt_file_name = p.name\n",
    "                save_path = str(save_dir / p.name)  # im.jpg, vid.mp4, ...\n",
    "            else:\n",
    "                p, im0, _ = path, im0s.copy(), getattr(dataset, 'frame', 0)\n",
    "                p = Path(p)  # to Path\n",
    "                # video file\n",
    "                if source.endswith(VID_FORMATS):\n",
    "                    txt_file_name = p.stem\n",
    "                    save_path = str(save_dir / p.name)  # im.jpg, vid.mp4, ...\n",
    "                # folder with imgs\n",
    "                else:\n",
    "                    txt_file_name = p.parent.name  # get folder name containing current img\n",
    "                    save_path = str(save_dir / p.parent.name)  # im.jpg, vid.mp4, ...\n",
    "            curr_frames[i] = im0\n",
    "\n",
    "            txt_path = str(save_dir / 'tracks' / txt_file_name)  # im.txt\n",
    "            s += '%gx%g ' % im.shape[2:]  # print string\n",
    "            imc = im0.copy() if save_crop else im0  # for save_crop\n",
    "\n",
    "            annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "            \n",
    "            if hasattr(tracker_list[i], 'tracker') and hasattr(tracker_list[i].tracker, 'camera_update'):\n",
    "                if prev_frames[i] is not None and curr_frames[i] is not None:  # camera motion compensation\n",
    "                    tracker_list[i].tracker.camera_update(prev_frames[i], curr_frames[i])\n",
    "\n",
    "            if det is not None and len(det):\n",
    "                if is_seg:\n",
    "                    shape = im0.shape\n",
    "                    # scale bbox first the crop masks\n",
    "                    if retina_masks:\n",
    "                        det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], shape).round()  # rescale boxes to im0 size\n",
    "                        masks.append(process_mask_native(proto[i], det[:, 6:], det[:, :4], im0.shape[:2]))  # HWC\n",
    "                    else:\n",
    "                        masks.append(process_mask(proto[i], det[:, 6:], det[:, :4], im.shape[2:], upsample=True))  # HWC\n",
    "                        det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], shape).round()  # rescale boxes to im0 size\n",
    "                else:\n",
    "                    det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()  # rescale boxes to im0 size\n",
    "\n",
    "                # Print results\n",
    "                for c in det[:, 5].unique():\n",
    "                    n = (det[:, 5] == c).sum()  # detections per class\n",
    "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "\n",
    "                # pass detections to strongsort\n",
    "                with dt[3]:\n",
    "                    outputs[i] = tracker_list[i].update(det.cpu(), im0)\n",
    "                    \n",
    "                # keep list of detected people\n",
    "                # every time yolo detects new person, check to find face that overlaps with person box, then do facial recognition on box\n",
    "                \n",
    "                # draw boxes for visualization\n",
    "                if len(outputs[i]) > 0:\n",
    "                    \n",
    "                    if is_seg:\n",
    "                        # Mask plotting\n",
    "                        annotator.masks(\n",
    "                            masks[i],\n",
    "                            colors=[colors(x, True) for x in det[:, 5]],\n",
    "                            im_gpu=torch.as_tensor(im0, dtype=torch.float16).to(device).permute(2, 0, 1).flip(0).contiguous() /\n",
    "                            255 if retina_masks else im[i]\n",
    "                        )\n",
    "                    \n",
    "                    for j, (output) in enumerate(outputs[i]):\n",
    "                        \n",
    "                        bbox = output[0:4]\n",
    "                        id = output[4]\n",
    "                        cls = output[5]\n",
    "                        conf = output[6]\n",
    "\n",
    "                        if save_txt:\n",
    "                            # to MOT format\n",
    "                            bbox_left = output[0]\n",
    "                            bbox_top = output[1]\n",
    "                            bbox_w = output[2] - output[0]\n",
    "                            bbox_h = output[3] - output[1]\n",
    "                            # Write MOT compliant results to file\n",
    "                            with open(txt_path + '.txt', 'a') as f:\n",
    "                                f.write(('%g ' * 10 + '\\n') % (frame_idx + 1, id, bbox_left,  # MOT format\n",
    "                                                               bbox_top, bbox_w, bbox_h, -1, -1, -1, i))\n",
    "\n",
    "                        if save_vid or save_crop or show_vid:  # Add bbox/seg to image\n",
    "                            c = int(cls)  # integer class\n",
    "                            id = int(id)  # integer id\n",
    "                            label = None if hide_labels else (f'{id} {names[c]}' if hide_conf else \\\n",
    "                                (f'{id} {conf:.2f}' if hide_class else f'{id} {names[c]} {conf:.2f}'))\n",
    "                            color = colors(c, True)\n",
    "                            annotator.box_label(bbox, label, color=color)\n",
    "                            \n",
    "                            if save_trajectories and tracking_method == 'strongsort':\n",
    "                                q = output[7]\n",
    "                                tracker_list[i].trajectory(im0, q, color=color)\n",
    "                            if save_crop:\n",
    "                                txt_file_name = txt_file_name if (isinstance(path, list) and len(path) > 1) else ''\n",
    "                                save_one_box(np.array(bbox, dtype=np.int16), imc, file=save_dir / 'crops' / txt_file_name / names[c] / f'{id}' / f'{p.stem}.jpg', BGR=True)\n",
    "                            \n",
    "            else:\n",
    "                pass\n",
    "                #tracker_list[i].tracker.pred_n_update_all_tracks()\n",
    "                \n",
    "            # Stream results\n",
    "            im0 = annotator.result()\n",
    "            if show_vid:\n",
    "                if platform.system() == 'Linux' and p not in windows:\n",
    "                    windows.append(p)\n",
    "                    cv2.namedWindow(str(p), cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)  # allow window resize (Linux)\n",
    "                    cv2.resizeWindow(str(p), im0.shape[1], im0.shape[0])\n",
    "                cv2.imshow(str(p), im0)\n",
    "                if cv2.waitKey(1) == ord('q'):  # 1 millisecond\n",
    "                    exit()\n",
    "\n",
    "            # Save results (image with detections)\n",
    "            if save_vid:\n",
    "                if vid_path[i] != save_path:  # new video\n",
    "                    vid_path[i] = save_path\n",
    "                    if isinstance(vid_writer[i], cv2.VideoWriter):\n",
    "                        vid_writer[i].release()  # release previous video writer\n",
    "                    if vid_cap:  # video\n",
    "                        fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                        w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                        h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                    else:  # stream\n",
    "                        fps, w, h = 30, im0.shape[1], im0.shape[0]\n",
    "                    save_path = str(Path(save_path).with_suffix('.mp4'))  # force *.mp4 suffix on results videos\n",
    "                    vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "                vid_writer[i].write(im0)\n",
    "\n",
    "            prev_frames[i] = curr_frames[i]\n",
    "            \n",
    "        # Print total time (preprocessing + inference + NMS + tracking)\n",
    "        LOGGER.info(f\"{s}{'' if len(det) else '(no detections), '}{sum([dt.dt for dt in dt if hasattr(dt, 'dt')]) * 1E3:.1f}ms\")\n",
    "\n",
    "    # Print results\n",
    "    t = tuple(x.t / seen * 1E3 for x in dt)  # speeds per image\n",
    "    LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS, %.1fms {tracking_method} update per image at shape {(1, 3, *imgsz)}' % t)\n",
    "    if save_txt or save_vid:\n",
    "        s = f\"\\n{len(list((save_dir / 'tracks').glob('*.txt')))} tracks saved to {save_dir / 'tracks'}\" if save_txt else ''\n",
    "        LOGGER.info(f\"Results saved to {colorstr('bold', save_dir)}{s}\")\n",
    "    if update:\n",
    "        strip_optimizer(yolo_weights)  # update model (to fix SourceChangeWarning)\n",
    "\n",
    "\n",
    "# def parse_opt():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--yolo-weights', nargs='+', type=Path, default=WEIGHTS / 'yolov8s-seg.pt', help='model.pt path(s)')\n",
    "#     parser.add_argument('--reid-weights', type=Path, default=WEIGHTS / 'osnet_x0_25_msmt17.pt')\n",
    "#     parser.add_argument('--tracking-method', type=str, default='botsort', help='strongsort, ocsort, bytetrack, botsort')\n",
    "#     parser.add_argument('--tracking-config', type=Path, default=None)\n",
    "#     parser.add_argument('--source', type=str, default='0', help='file/dir/URL/glob, 0 for webcam')  \n",
    "#     parser.add_argument('--imgsz', '--img', '--img-size', nargs='+', type=int, default=[640], help='inference size h,w')\n",
    "#     parser.add_argument('--conf-thres', type=float, default=0.5, help='confidence threshold')\n",
    "#     parser.add_argument('--iou-thres', type=float, default=0.5, help='NMS IoU threshold')\n",
    "#     parser.add_argument('--max-det', type=int, default=1000, help='maximum detections per image')\n",
    "#     parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')\n",
    "#     parser.add_argument('--show-vid', action='store_true', help='display tracking video results')\n",
    "#     parser.add_argument('--save-txt', action='store_true', help='save results to *.txt')\n",
    "#     parser.add_argument('--save-conf', action='store_true', help='save confidences in --save-txt labels')\n",
    "#     parser.add_argument('--save-crop', action='store_true', help='save cropped prediction boxes')\n",
    "#     parser.add_argument('--save-trajectories', action='store_true', help='save trajectories for each track')\n",
    "#     parser.add_argument('--save-vid', action='store_true', help='save video tracking results')\n",
    "#     parser.add_argument('--nosave', action='store_true', help='do not save images/videos')\n",
    "#     # class 0 is person, 1 is bycicle, 2 is car... 79 is oven\n",
    "#     parser.add_argument('--classes', nargs='+', type=int, help='filter by class: --classes 0, or --classes 0 2 3')\n",
    "#     parser.add_argument('--agnostic-nms', action='store_true', help='class-agnostic NMS')\n",
    "#     parser.add_argument('--augment', action='store_true', help='augmented inference')\n",
    "#     parser.add_argument('--visualize', action='store_true', help='visualize features')\n",
    "#     parser.add_argument('--update', action='store_true', help='update all models')\n",
    "#     parser.add_argument('--project', default=ROOT / 'runs' / 'track', help='save results to project/name')\n",
    "#     parser.add_argument('--name', default='exp', help='save results to project/name')\n",
    "#     parser.add_argument('--exist-ok', action='store_true', help='existing project/name ok, do not increment')\n",
    "#     parser.add_argument('--line-thickness', default=2, type=int, help='bounding box thickness (pixels)')\n",
    "#     parser.add_argument('--hide-labels', default=False, action='store_true', help='hide labels')\n",
    "#     parser.add_argument('--hide-conf', default=False, action='store_true', help='hide confidences')\n",
    "#     parser.add_argument('--hide-class', default=False, action='store_true', help='hide IDs')\n",
    "#     parser.add_argument('--half', action='store_true', help='use FP16 half-precision inference')\n",
    "#     parser.add_argument('--dnn', action='store_true', help='use OpenCV DNN for ONNX inference')\n",
    "#     parser.add_argument('--vid-stride', type=int, default=1, help='video frame-rate stride')\n",
    "#     parser.add_argument('--retina-masks', action='store_true', help='whether to plot masks in native resolution')\n",
    "#     opt = parser.parse_args()\n",
    "#     opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # expand\n",
    "#     opt.tracking_config = ROOT / 'trackers' / opt.tracking_method / 'configs' / (opt.tracking_method + '.yaml')\n",
    "#     print_args(vars(opt))\n",
    "#     return opt\n",
    "\n",
    "\n",
    "def main(opt):\n",
    "    check_requirements(requirements=ROOT / 'requirements.txt', exclude=('tensorboard', 'thop'))\n",
    "    run(**vars(opt))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    opt = parse_opt()\n",
    "    main(opt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4fddbe1-ea2a-43d2-9fef-b5cf1b77183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yolov8\n",
      "  Downloading yolov8-0.0.1-py37.py38.py39-none-any.whl (1.6 kB)\n",
      "Collecting yolov5\n",
      "  Downloading yolov5-7.0.11-py37.py38.py39.py310-none-any.whl (956 kB)\n",
      "Requirement already satisfied: roboflow>=0.2.29 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from yolov5->yolov8) (1.0.5)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from yolov5->yolov8) (1.3.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from yolov5->yolov8) (1.7.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from yolov5->yolov8) (6.0)\n",
      "Collecting boto3>=1.19.1\n",
      "  Downloading boto3-1.26.129-py3-none-any.whl (135 kB)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from yolov5->yolov8) (2.0.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from yolov5->yolov8) (5.8.0)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from yolov5->yolov8) (0.15.1)\n",
      "Requirement already satisfied: matplotlib>=3.2.2 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from yolov5->yolov8) (3.4.3)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from yolov5->yolov8) (4.65.0)\n",
      "Requirement already satisfied: ipython in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from yolov5->yolov8) (7.29.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from yolov5->yolov8) (1.22.4)\n",
      "Collecting tensorboard>=2.4.1\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from yolov5->yolov8) (8.4.0)\n",
      "Collecting sahi>=0.11.10\n",
      "  Downloading sahi-0.11.13-py3-none-any.whl (100 kB)\n",
      "Collecting fire\n",
      "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from yolov5->yolov8) (0.1.1.post2209072238)\n",
      "Collecting gitpython\n",
      "  Using cached GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "Collecting huggingface-hub>=0.12.0\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from yolov5->yolov8) (4.7.0.72)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from yolov5->yolov8) (0.11.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from yolov5->yolov8) (2.26.0)\n",
      "Collecting botocore<1.30.0,>=1.29.129\n",
      "  Downloading botocore-1.29.129-py3-none-any.whl (10.7 MB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from botocore<1.30.0,>=1.29.129->boto3>=1.19.1->yolov5->yolov8) (1.26.15)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from botocore<1.30.0,>=1.29.129->boto3>=1.19.1->yolov5->yolov8) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.12.0->yolov5->yolov8) (3.10.0.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.12.0->yolov5->yolov8) (2021.10.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.12.0->yolov5->yolov8) (21.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.12.0->yolov5->yolov8) (3.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->yolov5->yolov8) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->yolov5->yolov8) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from matplotlib>=3.2.2->yolov5->yolov8) (0.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.2.2->yolov5->yolov8) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from pandas>=1.1.4->yolov5->yolov8) (2021.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from requests>=2.23.0->yolov5->yolov8) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from requests>=2.23.0->yolov5->yolov8) (2.10)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from requests>=2.23.0->yolov5->yolov8) (2.0.4)\n",
      "Requirement already satisfied: wget in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow>=0.2.29->yolov5->yolov8) (3.2)\n",
      "Requirement already satisfied: chardet==4.0.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow>=0.2.29->yolov5->yolov8) (4.0.0)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow>=0.2.29->yolov5->yolov8) (0.10.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from roboflow>=0.2.29->yolov5->yolov8) (1.0.0)\n",
      "Collecting shapely>=1.8.0\n",
      "  Downloading shapely-2.0.1-cp39-cp39-win_amd64.whl (1.4 MB)\n",
      "Collecting click==8.0.4\n",
      "  Downloading click-8.0.4-py3-none-any.whl (97 kB)\n",
      "Collecting pybboxes==0.1.6\n",
      "  Downloading pybboxes-0.1.6-py3-none-any.whl (24 kB)\n",
      "Collecting terminaltables\n",
      "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from click==8.0.4->sahi>=0.11.10->yolov5->yolov8) (0.4.4)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->yolov5->yolov8) (0.37.0)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting grpcio>=1.48.2\n",
      "  Using cached grpcio-1.54.0-cp39-cp39-win_amd64.whl (4.1 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->yolov5->yolov8) (67.7.2)\n",
      "Collecting protobuf>=3.19.6\n",
      "  Downloading protobuf-4.22.4-cp39-cp39-win_amd64.whl (420 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from tensorboard>=2.4.1->yolov5->yolov8) (2.0.2)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard>=2.4.1->yolov5->yolov8) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->yolov5->yolov8) (3.6.0)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from torch>=1.7.0->yolov5->yolov8) (2.6.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from torch>=1.7.0->yolov5->yolov8) (1.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from torch>=1.7.0->yolov5->yolov8) (2.11.3)\n",
      "Collecting termcolor\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Using cached gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Using cached smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ipython->yolov5->yolov8) (3.0.20)\n",
      "Requirement already satisfied: decorator in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ipython->yolov5->yolov8) (5.1.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ipython->yolov5->yolov8) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ipython->yolov5->yolov8) (0.18.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ipython->yolov5->yolov8) (5.1.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ipython->yolov5->yolov8) (0.7.5)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ipython->yolov5->yolov8) (0.1.2)\n",
      "Requirement already satisfied: pygments in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from ipython->yolov5->yolov8) (2.10.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->yolov5->yolov8) (0.8.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->yolov5->yolov8) (0.2.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.7.0->yolov5->yolov8) (1.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\jorda\\anaconda3\\lib\\site-packages (from sympy->torch>=1.7.0->yolov5->yolov8) (1.2.1)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=1504ac297fb06ad427dbd74cd733f9688173921617f97ca3605f0cf938ccf27a\n",
      "  Stored in directory: c:\\users\\jorda\\appdata\\local\\pip\\cache\\wheels\\f7\\f1\\89\\b9ea2bf8f80ec027a88fef1d354b3816b4d3d29530988972f6\n",
      "Successfully built fire\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, jmespath, cachetools, termcolor, smmap, requests-oauthlib, google-auth, botocore, terminaltables, tensorboard-data-server, shapely, s3transfer, pybboxes, protobuf, markdown, grpcio, google-auth-oauthlib, gitdb, fire, click, absl-py, tensorboard, sahi, huggingface-hub, gitpython, boto3, yolov5, yolov8\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.3\n",
      "    Uninstalling click-8.0.3:\n",
      "      Successfully uninstalled click-8.0.3\n",
      "Successfully installed absl-py-1.4.0 boto3-1.26.129 botocore-1.29.129 cachetools-5.3.0 click-8.0.4 fire-0.5.0 gitdb-4.0.10 gitpython-3.1.31 google-auth-2.17.3 google-auth-oauthlib-1.0.0 grpcio-1.54.0 huggingface-hub-0.14.1 jmespath-1.0.1 markdown-3.4.3 oauthlib-3.2.2 protobuf-4.22.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 pybboxes-0.1.6 requests-oauthlib-1.3.1 rsa-4.9 s3transfer-0.6.1 sahi-0.11.13 shapely-2.0.1 smmap-5.0.0 tensorboard-2.13.0 tensorboard-data-server-0.7.0 termcolor-2.3.0 terminaltables-3.1.10 yolov5-7.0.11 yolov8-0.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mysql-connector-python 8.0.32 requires protobuf<=3.20.3,>=3.11.0, but you have protobuf 4.22.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install yolov8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a50df19e-5bc7-4eac-8abb-368b27f48b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\jorda\\\\OneDrive\\\\Desktop\\\\Research\\\\yolov8_tracking', 'C:\\\\Users\\\\jorda\\\\anaconda3\\\\python39.zip', 'C:\\\\Users\\\\jorda\\\\anaconda3\\\\DLLs', 'C:\\\\Users\\\\jorda\\\\anaconda3\\\\lib', 'C:\\\\Users\\\\jorda\\\\anaconda3', '', 'C:\\\\Users\\\\jorda\\\\AppData\\\\Roaming\\\\Python\\\\Python39\\\\site-packages', 'C:\\\\Users\\\\jorda\\\\anaconda3\\\\lib\\\\site-packages', 'C:\\\\Users\\\\jorda\\\\anaconda3\\\\lib\\\\site-packages\\\\dlib-19.24.0-py3.9-win-amd64.egg', 'C:\\\\Users\\\\jorda\\\\anaconda3\\\\lib\\\\site-packages\\\\locket-0.2.1-py3.9.egg', 'C:\\\\Users\\\\jorda\\\\anaconda3\\\\lib\\\\site-packages\\\\win32', 'C:\\\\Users\\\\jorda\\\\anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\jorda\\\\anaconda3\\\\lib\\\\site-packages\\\\Pythonwin', 'C:\\\\Users\\\\jorda\\\\anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions', 'C:\\\\Users\\\\jorda\\\\.ipython', '.']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\".\")\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bdefa77-8fdb-4595-8746-42793cd9f058",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'attempt_download' from 'ultralytics.yolo.utils.downloads' (C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\ultralytics\\yolo\\utils\\downloads.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13540/1903722039.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"yolov8.ultralytics.nn.autobackend\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# importlib.import_module('.yolov8.ultralytics.nn.autobackend', package='yolov8_tracking')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# import importlib.util\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# spec = importlib.util.find_spec('yolov8.ultralytics.nn.autobackend', \"AutoBackend\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Desktop\\Research\\yolov8_tracking\\yolov8\\ultralytics\\nn\\autobackend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLOGGER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mROOT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myaml_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchecks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_requirements\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_suffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownloads\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mattempt_download\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myolo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mxywh2xyxy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'attempt_download' from 'ultralytics.yolo.utils.downloads' (C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\ultralytics\\yolo\\utils\\downloads.py)"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.import_module(\"yolov8.ultralytics.nn.autobackend\")\n",
    "# importlib.import_module('.yolov8.ultralytics.nn.autobackend', package='yolov8_tracking')\n",
    "# import importlib.util\n",
    "# spec = importlib.util.find_spec('yolov8.ultralytics.nn.autobackend', \"AutoBackend\")\n",
    "# autobackend_module = importlib.util.module_from_spec(spec)\n",
    "# spec.loader.exec_module(autobackend_module)\n",
    "# AutoBackend = autobackend_module.AutoBackend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69d7b3ea-2080-45d0-8e03-49e8add992bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING  Ultralytics settings reset to defaults. \n",
      "This is normal and may be due to a recent ultralytics package update, but may have overwritten previous settings. \n",
      "You may view and update settings directly in 'C:\\Users\\jorda\\AppData\\Roaming\\Ultralytics\\settings.yaml'\n",
      "\u001b[34m\u001b[1mtrack: \u001b[0myolo_weights=C:\\Users\\jorda\\OneDrive\\Desktop\\Research\\yolov8_tracking\\weights\\yolov8s-seg.pt, reid_weights=C:\\Users\\jorda\\OneDrive\\Desktop\\Research\\yolov8_tracking\\weights\\osnet_x0_25_msmt17.pt, tracking_method=botsort, tracking_config=trackers\\botsort\\configs\\botsort.yaml, source=0, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.5, max_det=1000, device=, show_vid=False, save_txt=False, save_conf=False, save_crop=False, save_trajectories=False, save_vid=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\track, name=exp, exist_ok=False, line_thickness=2, hide_labels=False, hide_conf=False, hide_class=False, half=False, dnn=False, vid_stride=1, retina_masks=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m YOLOv8 requirements \"ultralytics==8.0.20\" \"numpy==1.23.1\" \"gdown\" \"lap\" \"filterpy\" not found, attempting AutoUpdate...\n",
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /simple/ultralytics/\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\jorda\\\\anaconda3\\\\Lib\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  Command 'pip install \"ultralytics==8.0.20\" \"numpy==1.23.1\" \"gdown\" \"lap\" \"filterpy\"  ' returned non-zero exit status 1.\n",
      "Ultralytics YOLOv8.0.20  Python-3.9.7 torch-2.0.0+cpu CPU\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8s-seg.pt to C:\\Users\\jorda\\OneDrive\\Desktop\\Research\\yolov8_tracking\\weights\\yolov8s-seg.pt...\n",
      "\n",
      "  0%|          | 0.00/22.8M [00:00<?, ?B/s]\n",
      "  1%|          | 144k/22.8M [00:00<00:16, 1.42MB/s]\n",
      "  3%|3         | 768k/22.8M [00:00<00:05, 4.16MB/s]\n",
      " 11%|#         | 2.42M/22.8M [00:00<00:02, 10.1MB/s]\n",
      " 18%|#7        | 4.06M/22.8M [00:00<00:01, 12.5MB/s]\n",
      " 27%|##7       | 6.23M/22.8M [00:00<00:01, 15.5MB/s]\n",
      " 34%|###3      | 7.70M/22.8M [00:00<00:01, 15.1MB/s]\n",
      " 42%|####2     | 9.61M/22.8M [00:00<00:00, 16.2MB/s]\n",
      " 49%|####8     | 11.2M/22.8M [00:00<00:00, 15.3MB/s]\n",
      " 56%|#####6    | 12.9M/22.8M [00:00<00:00, 15.9MB/s]\n",
      " 65%|######4   | 14.7M/22.8M [00:01<00:00, 16.6MB/s]\n",
      " 72%|#######2  | 16.5M/22.8M [00:01<00:00, 16.8MB/s]\n",
      " 80%|#######9  | 18.1M/22.8M [00:01<00:00, 16.1MB/s]\n",
      " 88%|########7 | 20.0M/22.8M [00:01<00:00, 16.7MB/s]\n",
      " 98%|#########8| 22.4M/22.8M [00:01<00:00, 19.1MB/s]\n",
      "100%|##########| 22.8M/22.8M [00:01<00:00, 15.8MB/s]\n",
      "\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11810560 parameters, 0 gradients, 42.6 GFLOPs\n",
      "1/1: 0...  Success (inf frames 640x480 at 30.00 FPS)\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\jorda\\OneDrive\\Desktop\\Research\\yolov8_tracking\\track.py\", line 365, in <module>\n",
      "    main(opt)\n",
      "  File \"C:\\Users\\jorda\\OneDrive\\Desktop\\Research\\yolov8_tracking\\track.py\", line 360, in main\n",
      "    run(**vars(opt))\n",
      "  File \"C:\\Users\\jorda\\anaconda3\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\jorda\\OneDrive\\Desktop\\Research\\yolov8_tracking\\track.py\", line 136, in run\n",
      "    tracker = create_tracker(tracking_method, tracking_config, reid_weights, device, half)\n",
      "  File \"C:\\Users\\jorda\\OneDrive\\Desktop\\Research\\yolov8_tracking\\trackers\\multi_tracker_zoo.py\", line 51, in create_tracker\n",
      "    from trackers.botsort.bot_sort import BoTSORT\n",
      "  File \"C:\\Users\\jorda\\OneDrive\\Desktop\\Research\\yolov8_tracking\\trackers\\botsort\\bot_sort.py\", line 6, in <module>\n",
      "    from trackers.botsort import  matching\n",
      "  File \"C:\\Users\\jorda\\OneDrive\\Desktop\\Research\\yolov8_tracking\\trackers\\botsort\\matching.py\", line 3, in <module>\n",
      "    import lap\n",
      "ModuleNotFoundError: No module named 'lap'\n",
      "Sentry is attempting to send 2 pending error messages\n",
      "Waiting up to 2 seconds\n",
      "Press Ctrl-Break to quit\n"
     ]
    }
   ],
   "source": [
    "!python track.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5499590d-996a-4438-af3d-2f4d25ad3148",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be83b692-4b67-436c-af0f-119ce864990c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jorda\\OneDrive\\Desktop\\Research\\yolov8_tracking/yolov8\n"
     ]
    }
   ],
   "source": [
    "# print(os.path.abspath(Path(\"__file__\").resolve().parents[0]))\n",
    "\n",
    "print(str(os.path.abspath(Path(\"__file__\").resolve().parents[0]) + '/yolov8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca507bde-22ec-46e8-881d-84ddd28dc27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    print(cpu, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a60d1c-c661-45ff-b12b-e43d12757505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.20  Python-3.9.7 torch-2.0.0+cpu CPU\n",
      "YOLOv8s-seg summary (fused): 195 layers, 11810560 parameters, 0 gradients, 42.6 GFLOPs\n",
      "WARNING  --img-size (640, 640) must be multiple of max stride 32, updating to [640, 640]\n",
      "WARNING  Environment does not support cv2.imshow() or PIL Image.show()\n",
      "\n",
      "1/1: 0...  Success (inf frames 640x480 at 30.00 FPS)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded pretrained weights from \"weights\\osnet_x0_25_msmt17.pt\"\n",
      "** The following layers are discarded due to unmatched keys or layer size: ['classifier.weight', 'classifier.bias']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 480x640 1 person, 610.8ms\n"
     ]
    }
   ],
   "source": [
    "torch.no_grad()\n",
    "\n",
    "# parameters\n",
    "source='0'\n",
    "yolo_weights=WEIGHTS / 'yolov8s-seg.pt'  # model.pt path(s),\n",
    "reid_weights=WEIGHTS / 'osnet_x0_25_msmt17.pt'  # model.pt path,\n",
    "tracking_method='strongsort'\n",
    "tracking_config = ROOT / 'trackers' / tracking_method / 'configs' / (tracking_method + '.yaml')\n",
    "imgsz=(640, 640)  # inference size (height, width)\n",
    "conf_thres=0.25  # confidence threshold\n",
    "iou_thres=0.45  # NMS IOU threshold\n",
    "max_det=1000  # maximum detections per image\n",
    "device=''  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "show_vid=False  # show results\n",
    "save_txt=False  # save results to *.txt\n",
    "save_conf=False  # save confidences in --save-txt labels\n",
    "save_crop=False  # save cropped prediction boxes\n",
    "save_trajectories=False  # save trajectories for each track\n",
    "save_vid=False  # save confidences in --save-txt labels\n",
    "nosave=False  # do not save images/videos\n",
    "classes=None  # filter by class: --class 0, or --class 0 2 3\n",
    "agnostic_nms=False  # class-agnostic NMS\n",
    "augment=False  # augmented inference\n",
    "visualize=False  # visualize features\n",
    "update=False  # update all models\n",
    "project=ROOT / 'runs' / 'track'  # save results to project/name\n",
    "name='exp'  # save results to project/name\n",
    "exist_ok=False  # existing project/name ok, do not increment\n",
    "line_thickness=2  # bounding box thickness (pixels)\n",
    "hide_labels=False  # hide labels\n",
    "hide_conf=False  # hide confidences\n",
    "hide_class=False  # hide IDs\n",
    "half=False  # use FP16 half-precision inference\n",
    "dnn=False  # use OpenCV DNN for ONNX inference\n",
    "vid_stride=1  # video frame-rate stride\n",
    "retina_masks=False\n",
    "\n",
    "\n",
    "source = str(source)\n",
    "save_img = not nosave and not source.endswith('.txt')  # save inference images\n",
    "is_file = Path(source).suffix[1:] in (VID_FORMATS)\n",
    "is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
    "webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file)\n",
    "if is_url and is_file:\n",
    "    source = check_file(source)  # download\n",
    "\n",
    "# Directories\n",
    "if not isinstance(yolo_weights, list):  # single yolo model\n",
    "    exp_name = yolo_weights.stem\n",
    "elif type(yolo_weights) is list and len(yolo_weights) == 1:  # single models after --yolo_weights\n",
    "    exp_name = Path(yolo_weights[0]).stem\n",
    "else:  # multiple models after --yolo_weights\n",
    "    exp_name = 'ensemble'\n",
    "exp_name = name if name else exp_name + \"_\" + reid_weights.stem\n",
    "save_dir = increment_path(Path(project) / exp_name, exist_ok=exist_ok)  # increment run\n",
    "(save_dir / 'tracks' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "# Load model\n",
    "device = select_device(device)\n",
    "is_seg = '-seg' in str(yolo_weights)\n",
    "model = AutoBackend(yolo_weights, device=device, dnn=dnn, fp16=half)\n",
    "stride, names, pt = model.stride, model.names, model.pt\n",
    "imgsz = check_imgsz(imgsz, stride=stride)  # check image size\n",
    "\n",
    "# Dataloader\n",
    "bs = 1\n",
    "if webcam:\n",
    "    show_vid = check_imshow(warn=True)\n",
    "    dataset = LoadStreams(\n",
    "        source,\n",
    "        imgsz=imgsz,\n",
    "        stride=stride,\n",
    "        auto=pt,\n",
    "        transforms=getattr(model.model, 'transforms', None),\n",
    "        vid_stride=vid_stride\n",
    "    )\n",
    "    bs = len(dataset)\n",
    "else:\n",
    "    dataset = LoadImages(\n",
    "        source,\n",
    "        imgsz=imgsz,\n",
    "        stride=stride,\n",
    "        auto=pt,\n",
    "        transforms=getattr(model.model, 'transforms', None),\n",
    "        vid_stride=vid_stride\n",
    "    )\n",
    "vid_path, vid_writer, txt_path = [None] * bs, [None] * bs, [None] * bs\n",
    "model.warmup(imgsz=(1 if pt or model.triton else bs, 3, *imgsz))  # warmup\n",
    "\n",
    "# Create as many strong sort instances as there are video sources\n",
    "tracker_list = []\n",
    "for i in range(bs):\n",
    "    tracker = create_tracker(tracking_method, tracking_config, reid_weights, device, half)\n",
    "    tracker_list.append(tracker, )\n",
    "    if hasattr(tracker_list[i], 'model'):\n",
    "        if hasattr(tracker_list[i].model, 'warmup'):\n",
    "            tracker_list[i].model.warmup()\n",
    "outputs = [None] * bs\n",
    "\n",
    "# Run tracking\n",
    "#model.warmup(imgsz=(1 if pt else bs, 3, *imgsz))  # warmup\n",
    "seen, windows, dt = 0, [], (Profile(), Profile(), Profile(), Profile())\n",
    "curr_frames, prev_frames = [None] * bs, [None] * bs\n",
    "\n",
    "\n",
    "\n",
    "for frame_idx, batch in enumerate(dataset):\n",
    "    path, im, im0s, vid_cap, s = batch\n",
    "    visualize = increment_path(save_dir / Path(path[0]).stem, mkdir=True) if visualize else False\n",
    "    with dt[0]:\n",
    "        im = torch.from_numpy(im).to(device)\n",
    "        im = im.half() if half else im.float()  # uint8 to fp16/32\n",
    "        im /= 255.0  # 0 - 255 to 0.0 - 1.0\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]  # expand for batch dim\n",
    "\n",
    "    # Inference\n",
    "    with dt[1]:\n",
    "        preds = model(im, augment=augment, visualize=visualize)\n",
    "\n",
    "    # Apply NMS\n",
    "    with dt[2]:\n",
    "        if is_seg:\n",
    "            masks = []\n",
    "            p = non_max_suppression(preds[0], conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det, nm=32)\n",
    "            proto = preds[1][-1]\n",
    "        else:\n",
    "            p = non_max_suppression(preds, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
    "\n",
    "    # Process detections\n",
    "    for i, det in enumerate(p):  # detections per image\n",
    "        seen += 1\n",
    "        if webcam:  # bs >= 1\n",
    "            p, im0, _ = path[i], im0s[i].copy(), dataset.count\n",
    "            p = Path(p)  # to Path\n",
    "            s += f'{i}: '\n",
    "            txt_file_name = p.name\n",
    "            save_path = str(save_dir / p.name)  # im.jpg, vid.mp4, ...\n",
    "        else:\n",
    "            p, im0, _ = path, im0s.copy(), getattr(dataset, 'frame', 0)\n",
    "            p = Path(p)  # to Path\n",
    "            # video file\n",
    "            if source.endswith(VID_FORMATS):\n",
    "                txt_file_name = p.stem\n",
    "                save_path = str(save_dir / p.name)  # im.jpg, vid.mp4, ...\n",
    "            # folder with imgs\n",
    "            else:\n",
    "                txt_file_name = p.parent.name  # get folder name containing current img\n",
    "                save_path = str(save_dir / p.parent.name)  # im.jpg, vid.mp4, ...\n",
    "        curr_frames[i] = im0\n",
    "\n",
    "        txt_path = str(save_dir / 'tracks' / txt_file_name)  # im.txt\n",
    "        s += '%gx%g ' % im.shape[2:]  # print string\n",
    "        imc = im0.copy() if save_crop else im0  # for save_crop\n",
    "\n",
    "        annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "\n",
    "        if hasattr(tracker_list[i], 'tracker') and hasattr(tracker_list[i].tracker, 'camera_update'):\n",
    "            if prev_frames[i] is not None and curr_frames[i] is not None:  # camera motion compensation\n",
    "                tracker_list[i].tracker.camera_update(prev_frames[i], curr_frames[i])\n",
    "\n",
    "        if det is not None and len(det):\n",
    "            if is_seg:\n",
    "                shape = im0.shape\n",
    "                # scale bbox first the crop masks\n",
    "                if retina_masks:\n",
    "                    det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], shape).round()  # rescale boxes to im0 size\n",
    "                    masks.append(process_mask_native(proto[i], det[:, 6:], det[:, :4], im0.shape[:2]))  # HWC\n",
    "                else:\n",
    "                    masks.append(process_mask(proto[i], det[:, 6:], det[:, :4], im.shape[2:], upsample=True))  # HWC\n",
    "                    det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], shape).round()  # rescale boxes to im0 size\n",
    "            else:\n",
    "                det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()  # rescale boxes to im0 size\n",
    "\n",
    "            # Print results\n",
    "            for c in det[:, 5].unique():\n",
    "                n = (det[:, 5] == c).sum()  # detections per class\n",
    "                s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "    \n",
    "            # pass detections to strongsort\n",
    "            with torch.no_grad():\n",
    "\n",
    "                with dt[3]:\n",
    "                    outputs[i] = tracker_list[i].update(det.cpu(), im0)\n",
    "\n",
    "            # keep list of detected people\n",
    "            # every time yolo detects new person, check to find face that overlaps with person box, then do facial recognition on box\n",
    "\n",
    "            # draw boxes for visualization\n",
    "            if len(outputs[i]) > 0:\n",
    "\n",
    "                if is_seg:\n",
    "                    # Mask plotting\n",
    "                    annotator.masks(\n",
    "                        masks[i],\n",
    "                        colors=[colors(x, True) for x in det[:, 5]],\n",
    "                        im_gpu=torch.as_tensor(im0, dtype=torch.float16).to(device).permute(2, 0, 1).flip(0).contiguous() /\n",
    "                        255 if retina_masks else im[i]\n",
    "                    )\n",
    "\n",
    "                for j, (output) in enumerate(outputs[i]):\n",
    "\n",
    "                    bbox = output[0:4]\n",
    "                    id = output[4]\n",
    "                    cls = output[5]\n",
    "                    conf = output[6]\n",
    "\n",
    "                    if save_txt:\n",
    "                        # to MOT format\n",
    "                        bbox_left = output[0]\n",
    "                        bbox_top = output[1]\n",
    "                        bbox_w = output[2] - output[0]\n",
    "                        bbox_h = output[3] - output[1]\n",
    "                        # Write MOT compliant results to file\n",
    "                        with open(txt_path + '.txt', 'a') as f:\n",
    "                            f.write(('%g ' * 10 + '\\n') % (frame_idx + 1, id, bbox_left,  # MOT format\n",
    "                                                           bbox_top, bbox_w, bbox_h, -1, -1, -1, i))\n",
    "\n",
    "                    if save_vid or save_crop or show_vid:  # Add bbox/seg to image\n",
    "                        c = int(cls)  # integer class\n",
    "                        id = int(id)  # integer id\n",
    "                        label = None if hide_labels else (f'{id} {names[c]}' if hide_conf else \\\n",
    "                            (f'{id} {conf:.2f}' if hide_class else f'{id} {names[c]} {conf:.2f}'))\n",
    "                        color = colors(c, True)\n",
    "                        annotator.box_label(bbox, label, color=color)\n",
    "\n",
    "                        if save_trajectories and tracking_method == 'strongsort':\n",
    "                            q = output[7]\n",
    "                            tracker_list[i].trajectory(im0, q, color=color)\n",
    "                        if save_crop:\n",
    "                            txt_file_name = txt_file_name if (isinstance(path, list) and len(path) > 1) else ''\n",
    "                            save_one_box(np.array(bbox, dtype=np.int16), imc, file=save_dir / 'crops' / txt_file_name / names[c] / f'{id}' / f'{p.stem}.jpg', BGR=True)\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "            #tracker_list[i].tracker.pred_n_update_all_tracks()\n",
    "\n",
    "        # Stream results\n",
    "        im0 = annotator.result()\n",
    "        if show_vid:\n",
    "            if platform.system() == 'Linux' and p not in windows:\n",
    "                windows.append(p)\n",
    "                cv2.namedWindow(str(p), cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)  # allow window resize (Linux)\n",
    "                cv2.resizeWindow(str(p), im0.shape[1], im0.shape[0])\n",
    "            cv2.imshow(str(p), im0)\n",
    "            if cv2.waitKey(1) == ord('q'):  # 1 millisecond\n",
    "                exit()\n",
    "\n",
    "        # Save results (image with detections)\n",
    "        if save_vid:\n",
    "            if vid_path[i] != save_path:  # new video\n",
    "                vid_path[i] = save_path\n",
    "                if isinstance(vid_writer[i], cv2.VideoWriter):\n",
    "                    vid_writer[i].release()  # release previous video writer\n",
    "                if vid_cap:  # video\n",
    "                    fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                    w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                    h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                else:  # stream\n",
    "                    fps, w, h = 30, im0.shape[1], im0.shape[0]\n",
    "                save_path = str(Path(save_path).with_suffix('.mp4'))  # force *.mp4 suffix on results videos\n",
    "                vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "            vid_writer[i].write(im0)\n",
    "\n",
    "        prev_frames[i] = curr_frames[i]\n",
    "\n",
    "    # Print total time (preprocessing + inference + NMS + tracking)\n",
    "    LOGGER.info(f\"{s}{'' if len(det) else '(no detections), '}{sum([dt.dt for dt in dt if hasattr(dt, 'dt')]) * 1E3:.1f}ms\")\n",
    "\n",
    "# Print results\n",
    "t = tuple(x.t / seen * 1E3 for x in dt)  # speeds per image\n",
    "LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS, %.1fms {tracking_method} update per image at shape {(1, 3, *imgsz)}' % t)\n",
    "if save_txt or save_vid:\n",
    "    s = f\"\\n{len(list((save_dir / 'tracks').glob('*.txt')))} tracks saved to {save_dir / 'tracks'}\" if save_txt else ''\n",
    "    LOGGER.info(f\"Results saved to {colorstr('bold', save_dir)}{s}\")\n",
    "if update:\n",
    "    strip_optimizer(yolo_weights)  # update model (to fix SourceChangeWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea62d4e-7c0d-442d-93e4-9e52a08cd880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
